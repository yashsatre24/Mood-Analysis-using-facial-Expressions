{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array=cv2.imread(\"Training/0/Training_68010171.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415779e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854bc241",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebdbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datadirectory=\"Training/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classes=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cd91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in Classes:\n",
    "    path=os.path.join(Datadirectory, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img))\n",
    "        plt.imshow(cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=224\n",
    "new_array=cv2.resize(img_array,(img_size,img_size))\n",
    "plt.imshow(cv2.cvtColor(new_array,cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a002d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_Data=[]\n",
    "\n",
    "def create_training_Data():\n",
    "    for category in Classes:\n",
    "        path=os.path.join(Datadirectory, category)\n",
    "        class_num=Classes.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img))\n",
    "                new_array=cv2.resize(img_array,(img_size,img_size))\n",
    "                training_Data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd991f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(training_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333aea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e7013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for features ,label in training_Data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X=np.array(X).reshape(-1,img_size,img_size,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d47184",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255.0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ca3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b50dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3e214",
   "metadata": {},
   "source": [
    "# Deep learning model for training - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3c113",
   "metadata": {},
   "source": [
    "# Transfer learning -Tuning ,weights will start from last check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a446bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_input=model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output=model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e24634",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output=layers.Dense(128)(base_output)\n",
    "final_output=layers.Activation('relu')(final_output)\n",
    "final_output=layers.Dense(64)(final_output)\n",
    "final_output=layers.Activation('relu')(final_output)\n",
    "final_output=layers.Dense(7,activation='softmax')(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d39d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106eb471",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=keras.Model(inputs=base_input,outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(X,Y, epochs =25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522cf62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save('Final_model_95p07.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ae96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=tf.keras.models.load_model('Final_model_95p07.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5de1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=cv2.imread(\"happyboy.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ee5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85764eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33458632",
   "metadata": {},
   "source": [
    "# we need face detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66aafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaeac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=faceCascade.detectMultiScale(gray,1.1,4)\n",
    "for x,y,w,h in faces:\n",
    "    roi_gray=gray[y:y+h,x:x+w]\n",
    "    roi_color=frame[y:y+h,x:x+w]\n",
    "    cv2.rectangle(frame,(x,y),(x+w, y+h),(225,0,0),2)\n",
    "    facess=faceCascade.detectMultiScale(roi_gray)\n",
    "    if len(facess)==0:\n",
    "        print(\"Face not Detected\")\n",
    "    else:\n",
    "        for(ex,ey,ew,eh) in facess:\n",
    "            face_roi=roi_color[ey: ey+eh, ex:ex+ew]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(face_roi,cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image=cv2.resize(face_roi,(224,224))\n",
    "final_image=np.expand_dims(final_image,axis=0)\n",
    "final_image=final_image/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions=new_model.predict(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6baa8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(Predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f7951",
   "metadata": {},
   "source": [
    "# LIVE DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "path=\"haarcascade_frontalface_default.xml\"\n",
    "font_scale=1.5\n",
    "font=cv2.FONT_HERSHEY_PLAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f94634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the rectangular background to white\n",
    "\n",
    "rectangle_bgr=(255,255,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd795d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a black image\n",
    "\n",
    "img=np.zeros((500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set some text\n",
    "\n",
    "text=\"Some text in a box!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31217d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the width and height of the text box\n",
    "\n",
    "(text_width,text_height)=cv2.getTextSize(text,font,fontScale=font_scale,thickness=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the text start position\n",
    "\n",
    "text_offset_x=10\n",
    "text_offset_y=img.shape[0]-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d349440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the coords of the box with a small padding of two pixels\n",
    "\n",
    "box_coords=((text_offset_x,text_offset_y),(text_offset_x + text_width +2,text_offset_y - text_height-2))\n",
    "cv2.rectangle(img,box_coords[0],box_coords[1], rectangle_bgr, cv2.FILLED)\n",
    "cv2.putText(img, text,(text_offset_x,text_offset_y),font,fontScale=font_scale,color=(0,0,0),thickness=1)\n",
    "\n",
    "cap=cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc06bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the webcam is opened correctly\n",
    "\n",
    "if not cap.isOpened():\n",
    "    cap=cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "    \n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #print(faceCascade.empty())\n",
    "    faces=faceCascade.detectMultiScale(gray,1.1,4)\n",
    "    for x,y,w,h in faces:\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_color=frame[y:y+h,x:x+w]\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        facess=faceCascade.detectMultiScale(roi_gray)\n",
    "        if len(facess)==0:\n",
    "            print(\"Face not Detected\")\n",
    "        else:\n",
    "            for(ex,ey,ew,eh) in facess:\n",
    "                face_roi=roi_color[ey:ey+eh,ex:ex+ew]\n",
    "                \n",
    "    final_image=cv2.resize(face_roi,(224,224))\n",
    "    final_image=np.expand_dims(final_image,axis=0)\n",
    "    final_image=final_image/255.0\n",
    "    \n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    Predictions=new_model.predict(final_image)\n",
    "    \n",
    "    font_scale=1.5\n",
    "    font=cv2.FONT_HERSHEY_PLAIN\n",
    "    \n",
    "    if(np.argmax(Predictions)==0):\n",
    "        status=\"Angry\"\n",
    "        \n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        \n",
    "        #Draw black background rectangle\n",
    "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "        \n",
    "        #ADD text\n",
    "        cv2.putText(frame,status,(x1 + int(w1/10),y1+ int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        \n",
    "        cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "        \n",
    "    elif(np.argmax(Predictions)==1):\n",
    "        status=\"Disgust\"\n",
    "        \n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        \n",
    "        #Draw black background rectangle\n",
    "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "        \n",
    "        #ADD text\n",
    "        cv2.putText(frame,status,(x1 + int(w1/10),y1+ int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        \n",
    "        cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "        \n",
    "    elif(np.argmax(Predictions)==2):\n",
    "        status=\"Fear\"\n",
    "        \n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        \n",
    "        #Draw black background rectangle\n",
    "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "        \n",
    "        #ADD text\n",
    "        cv2.putText(frame,status,(x1 + int(w1/10),y1+ int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        \n",
    "        cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "        \n",
    "    elif(np.argmax(Predictions)==3):\n",
    "        status=\"Happy\"\n",
    "        \n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        \n",
    "        #Draw black background rectangle\n",
    "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "        \n",
    "        #ADD text\n",
    "        cv2.putText(frame,status,(x1 + int(w1/10),y1+ int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        \n",
    "        cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "        \n",
    "    elif(np.argmax(Predictions)==4):\n",
    "        status=\"Sad\"\n",
    "        \n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        \n",
    "        #Draw black background rectangle\n",
    "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "        \n",
    "        #ADD text\n",
    "        cv2.putText(frame,status,(x1 + int(w1/10),y1+ int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        \n",
    "        cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "        \n",
    "    elif(np.argmax(Predictions)==5):\n",
    "        status=\"Surprise\"\n",
    "        \n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        \n",
    "        #Draw black background rectangle\n",
    "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "        \n",
    "        #ADD text\n",
    "        cv2.putText(frame,status,(x1 + int(w1/10),y1+ int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        \n",
    "        cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        status=\"Neutral\"\n",
    "        \n",
    "        x1,y1,w1,h1 = 0,0,175,75\n",
    "        \n",
    "        #Draw black background rectangle\n",
    "        cv2.rectangle(frame,(x1,x1),(x1+w1,y1+h1),(0,0,0),-1)\n",
    "        \n",
    "        #ADD text\n",
    "        cv2.putText(frame,status,(x1 + int(w1/10),y1+ int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,0,255),2)\n",
    "        \n",
    "        cv2.putText(frame,status,(100,150),font,3,(0,0,255),2,cv2.LINE_4)\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255))\n",
    "        \n",
    "        \n",
    "    cv2.imshow('face emotion recognition',frame)\n",
    "    if cv2.waitKey(2) & 0xFF== ord('q'):\n",
    "            break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c6240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f5438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f6e610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
